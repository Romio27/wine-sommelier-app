{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Models initialization",
   "id": "9b9ae8fda6d3634c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-20T16:55:53.725917Z",
     "start_time": "2025-11-20T16:55:53.682602Z"
    }
   },
   "source": [
    "import json\n",
    "from os import stat_result\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT = os.getenv(\"EMBEDDING_DEPLOYMENT_NAME\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY missing\"\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT,\n",
    "    base_url=None,\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0.0)\n",
    "print(\"LLM ready.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ready.\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RAG implementation",
   "id": "87d86d00e29fc96a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:24:51.080629Z",
     "start_time": "2025-11-20T14:24:45.852855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jrobischon/wikipedia-movie-plots\")\n",
    "path += \"/wiki_movie_plots_deduped.csv\"\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.head()\n",
    "from datetime import datetime, date\n",
    "from typing import Optional, Iterable, List, Dict, Any\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def _to_python(val: Any) -> Any:\n",
    "    \"\"\"Make values JSON/metadata-friendly (convert numpy scalars, NaT, timestamps, etc.).\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    if isinstance(val, (np.generic,)):\n",
    "        return val.item()\n",
    "    if isinstance(val, (pd.Timestamp, datetime, date)):\n",
    "        return val.isoformat()\n",
    "    return val\n",
    "\n",
    "def df_to_documents(\n",
    "    df: pd.DataFrame,\n",
    "    text_col: str = \"plot\",\n",
    "    meta_cols: Optional[Iterable[str]] = None,\n",
    "    drop_na_text: bool = True,\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Convert a DataFrame to LangChain Documents.\n",
    "    - `text_col` becomes page_content.\n",
    "    - All other columns (or `meta_cols` if provided) become metadata.\n",
    "    - Rows with missing text are dropped by default.\n",
    "    \"\"\"\n",
    "    if text_col not in df.columns:\n",
    "        raise ValueError(f\"text_col '{text_col}' not found in DataFrame columns: {list(df.columns)}\")\n",
    "\n",
    "    work = df.copy()\n",
    "\n",
    "    if drop_na_text:\n",
    "        work = work[~work[text_col].isna()]\n",
    "\n",
    "    # Decide which columns become metadata\n",
    "    if meta_cols is None:\n",
    "        meta_cols = [c for c in work.columns if c != text_col]\n",
    "    else:\n",
    "        for c in meta_cols:\n",
    "            if c not in work.columns:\n",
    "                raise ValueError(f\"meta_col '{c}' not found in DataFrame\")\n",
    "\n",
    "    docs: List[Document] = []\n",
    "    for _, row in work.iterrows():\n",
    "        page_content = \"\" if pd.isna(row[text_col]) else str(row[text_col])\n",
    "        metadata: Dict[str, Any] = {col: _to_python(row[col]) for col in meta_cols}\n",
    "        docs.append(Document(page_content=page_content, metadata=metadata))\n",
    "    return docs\n",
    "\n",
    "docs = df_to_documents(df, text_col=\"Plot\")"
   ],
   "id": "79ff2565177c1de1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\oleksiy.hoyev\\.cache\\kagglehub\\datasets\\jrobischon\\wikipedia-movie-plots\\versions\\1/wiki_movie_plots_deduped.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:00:15.635703Z",
     "start_time": "2025-11-20T13:41:51.003630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector_store = FAISS.from_documents(docs[:10000], embeddings)\n",
    "print(\"FAISS vector store created from movie plots.\")"
   ],
   "id": "93e462914312a8cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vector store created from movie plots.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:25:28.201376Z",
     "start_time": "2025-11-20T14:25:28.197206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Persistence for vector store\n",
    "PERSIST_DIR = \"./faiss_index\"\n",
    "# os.makedirs(PERSIST_DIR, exist_ok=True)\n",
    "# vector_store.save_local(PERSIST_DIR)\n",
    "# print(f\"Saved FAISS index to {PERSIST_DIR}\")"
   ],
   "id": "2d411e414d399cbe",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:35:37.650081Z",
     "start_time": "2025-11-20T16:35:37.324183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector_store = FAISS.load_local(PERSIST_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "print(\"Reloaded store size:\", len(reloaded.index_to_docstore_id))"
   ],
   "id": "b18ee11ecf5eb12b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded store size: 10000\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:35:42.343509Z",
     "start_time": "2025-11-20T16:35:42.323257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"{json.dumps(d.metadata)}: {d.page_content}\" for d in docs)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use the provided context to answer the user's question. If unsure, say you don't know.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\\n\\nAnswer:\")\n",
    "])\n",
    "\n",
    "#  \"score_threshold\": 1.3\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG chain constructed.\")"
   ],
   "id": "44b226f6d3d5a055",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain constructed.\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tool Calling",
   "id": "c1e7fe9bb91175dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:35:55.761112Z",
     "start_time": "2025-11-20T16:35:55.756056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool"
   ],
   "id": "4d9fc6abd31d6354",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:36:37.660116Z",
     "start_time": "2025-11-20T16:36:37.637645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from random import randint\n",
    "\n",
    "\n",
    "@tool(description=\"Simple addition tool. Call it whenever user requests to add 2 numbers. \"\n",
    "                  \"If more numbers are given, split into multiple calls.\")\n",
    "def add_numbers(a: Annotated[float, \"First operand. Floating point value. Required.\"],\n",
    "                b: Annotated[float, \"Second operand. Floating point value. Required.\"]) -> float:\n",
    "    return a+b\n",
    "\n",
    "\n",
    "@tool(description=\"Fetch current weather for a given city. Call it when user asks for current weather.\")\n",
    "def fetch_current_weather(\n",
    "        country: Annotated[str, \"Name of the country where the city is located. \"\n",
    "                                \"Required. Must be a country code (i.e. UK, UA, US, etc.)\" ],\n",
    "        city: Annotated[str, \"Name of the city to fetch weather for. Optional.\"]) -> str:\n",
    "    return f\"Weather in {country} {city if city else ''}:  Sunny, {randint(-20, 40)}C\""
   ],
   "id": "fa02d470c3421d1c",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:42:53.924230Z",
     "start_time": "2025-11-20T16:42:10.180920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.runnables.utils import Output\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant that can use tools to answer user questions.\"),\n",
    "    HumanMessage(\"What is the weather in Lviv? Also, add 5.5 and 10.2.\")\n",
    "]\n",
    "\n",
    "tools = {tool.name: tool for tool in [add_numbers, fetch_current_weather]}\n",
    "\n",
    "tools = {\n",
    "    \"add_numbers\": add_numbers,\n",
    "    \"fetch_current_weather\": fetch_current_weather\n",
    "}\n",
    "\n",
    "llm_with_tools: Runnable = llm.bind_tools([add_numbers, fetch_current_weather])\n",
    "response: Output = llm_with_tools.invoke(messages)\n",
    "messages.append(response)"
   ],
   "id": "a734ef1b85ac30d1",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:42:53.981466Z",
     "start_time": "2025-11-20T16:42:53.969202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "pprint(response.content)\n",
    "pprint(response.tool_calls)"
   ],
   "id": "78dfb90ebf6b808e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "[{'args': {'city': 'Lviv', 'country': 'UA'},\n",
      "  'id': 'call_MVD0CHDxpVOLZoCMWLhVDizv',\n",
      "  'name': 'fetch_current_weather',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'a': 5.5, 'b': 10.2},\n",
      "  'id': 'call_VsnwFu3BoTDhGLcPif5rbutl',\n",
      "  'name': 'add_numbers',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:45:34.266340Z",
     "start_time": "2025-11-20T16:45:34.255578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tool_results = []\n",
    "for tool in response.tool_calls:\n",
    "    res = tools[tool[\"name\"]].invoke({**tool['args']})\n",
    "    print(f\"Tool called: {tool['name']} with args {tool['args']} -> returned {res}\")\n",
    "    tool_results.append(ToolMessage(res, tool_call_id=tool['id']))\n",
    "messages += tool_results"
   ],
   "id": "d31a04e961dd4c98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool called: fetch_current_weather with args {'country': 'UA', 'city': 'Lviv'} -> returned Weather in UA Lviv:  Sunny, 29C\n",
      "Tool called: add_numbers with args {'a': 5.5, 'b': 10.2} -> returned 15.7\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:48:45.586430Z",
     "start_time": "2025-11-20T16:48:01.639466Z"
    }
   },
   "cell_type": "code",
   "source": "response: Output = llm_with_tools.invoke(messages)",
   "id": "51331d0a723dd75f",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:50:33.071591Z",
     "start_time": "2025-11-20T16:50:33.055385Z"
    }
   },
   "cell_type": "code",
   "source": "response.content",
   "id": "78af50fcf8590ebe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in Lviv, Ukraine is sunny with a temperature of 29°C.\\n\\nAlso, the sum of 5.5 and 10.2 is 15.7.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Custom Conversational Agent with Tool Calling",
   "id": "168993909b71558d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:56:02.491830Z",
     "start_time": "2025-11-20T16:56:02.485464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Conversation:\n",
    "    def __init__(self, llm):\n",
    "        self.messages = [\n",
    "            SystemMessage(\"You are a helpful assistant that can use tools to answer user questions.\")\n",
    "        ]\n",
    "        self.llm = llm.bind_tools([add_numbers, fetch_current_weather])\n",
    "        self.tools = {\n",
    "            \"add_numbers\": add_numbers,\n",
    "            \"fetch_current_weather\": fetch_current_weather\n",
    "        }\n",
    "\n",
    "    def execute_tools(self, message: AIMessage) -> List[ToolMessage]:\n",
    "        if not message.tool_calls:\n",
    "            return []\n",
    "        tool_results = []\n",
    "        for tool in message.tool_calls:\n",
    "            res = self.tools[tool[\"name\"]].invoke({**tool['args']})\n",
    "            print(f\"Tool called: {tool['name']} with args {tool['args']} -> returned {res}\")\n",
    "            tool_results.append(ToolMessage(res, tool_call_id=tool['id']))\n",
    "        return tool_results\n",
    "\n",
    "    def turn(self):\n",
    "        response: Output = self.llm.invoke(self.messages)\n",
    "        self.messages.append(response)\n",
    "        self.messages += self.execute_tools(response)\n",
    "\n",
    "    def __call__(self, user_input: str):\n",
    "        self.messages.append(HumanMessage(user_input))\n",
    "        while not isinstance(self.messages[-1], AIMessage):\n",
    "            self.turn()\n",
    "        return self.messages[-1]\n"
   ],
   "id": "21930a7193d413a9",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T16:56:03.339313Z",
     "start_time": "2025-11-20T16:56:03.328676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create new conversation\n",
    "conv = Conversation(llm)"
   ],
   "id": "fa358f80f28e5899",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:00:26.165866Z",
     "start_time": "2025-11-20T16:59:41.846767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = \"give me all weather statuses from conversation.\"\n",
    "response = conv(message)\n",
    "pprint(response.content)"
   ],
   "id": "aea6f2dba67910a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Here are all the weather statuses from our conversation:\\n'\n",
      " '\\n'\n",
      " '1. Brazil: Sunny, 13°C\\n'\n",
      " '2. Ukraine: Sunny, 2°C\\n'\n",
      " '3. New York, US: Sunny, -19°C\\n'\n",
      " '\\n'\n",
      " 'Let me know if you need weather information for any other locations!')\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dad8610052e50017"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LangGraph Agent with RAG and Tool Calling",
   "id": "b7645ab9d610df77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:01:40.431242Z",
     "start_time": "2025-11-20T17:01:40.426430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import MessagesState"
   ],
   "id": "fab405fc168afbad",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:12:01.382644Z",
     "start_time": "2025-11-20T17:12:01.365113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tools = [add_numbers, fetch_current_weather, rag_tool]\n",
    "tool_node = ToolNode(tools)\n",
    "agent_node = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    state_schema=MessagesState\n",
    ")\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "def build_graph():\n",
    "    workflow = StateGraph(MessagesState)\n",
    "\n",
    "    workflow.add_node(\"agent\", agent_node)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "    workflow.add_edge(START, \"agent\")\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return workflow.compile()"
   ],
   "id": "f253f51ebf4c3832",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:12:01.933428Z",
     "start_time": "2025-11-20T17:12:01.923524Z"
    }
   },
   "cell_type": "code",
   "source": "graph = build_graph()",
   "id": "5e625a8c98a73fd",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:12:54.086842Z",
     "start_time": "2025-11-20T17:12:02.571881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = graph.invoke({\n",
    "    \"messages\": [\n",
    "        SystemMessage(\"You are a helpful assistant that can use tools to answer user questions.\"),\n",
    "        HumanMessage(\"give me a move with sci-fy plot\")\n",
    "    ]\n",
    "})"
   ],
   "id": "2bc46d1a273dae00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG tool called with question: Give me a movie with a sci-fi plot.\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:12:54.127866Z",
     "start_time": "2025-11-20T17:12:54.120699Z"
    }
   },
   "cell_type": "code",
   "source": "pprint(res[\"messages\"][-1].content)",
   "id": "a2a6b16426250c7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Here's a movie with a sci-fi plot: Monster A Go-Go (1965).\\n\"\n",
      " '\\n'\n",
      " 'The story is about an astronaut named Frank Douglas who disappears after '\n",
      " 'returning to Earth. Afterward, a large, radioactive, humanoid monster '\n",
      " 'appears—suggesting the astronaut was either replaced by or turned into this '\n",
      " 'creature. Scientists and the military try to capture it as chaos unfolds. In '\n",
      " \"a twist ending, it's revealed Douglas was actually rescued elsewhere, \"\n",
      " 'hinting that the monster may have been an alien impostor.\\n'\n",
      " '\\n'\n",
      " 'Let me know if you want a more popular or different kind of sci-fi movie!')\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:11:59.153648Z",
     "start_time": "2025-11-20T17:11:59.144736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Task during workshop: add rag as a tool in the LangGraph agent\n",
    "from langchain.tools import tool\n",
    "@tool(description=\"Use RAG to answer questions based on movie plots dataset.\")\n",
    "def rag_tool(question: Annotated[str, \"Question to be answered based on movie plots. Required.\"]) -> str:\n",
    "    print(\"RAG tool called with question:\", question)\n",
    "    return rag_chain.invoke(question)"
   ],
   "id": "72e90a6041a4aa4e",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b4f1f5d65f0ee4b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bigger workflow with task planning, react agent, conversation summarization, etc.",
   "id": "a8056c1bba7abdc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:15:49.634080Z",
     "start_time": "2025-11-20T17:15:49.620370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Lets create artificial tools as in example with files upload\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(description=\"Upload file text to google drive. Call it when user wants to upload a file to cloud.\"\n",
    "                  \"It is a main method to upload something. Always use it when there are some files to be saved.\")\n",
    "def upload_to_google_drive(file_name: Annotated[str, \"Name of the file to be uploaded. Required.\"],\n",
    "                           file_content: Annotated[str, \"Content of the file to be uploaded. Required.\"]) -> str:\n",
    "    print(f\"Failed to upload {file_name} to Google Drive.\")\n",
    "    return f\"Failed to upload {file_name} to Google Drive.\"\n",
    "\n",
    "@tool(description=\"Upload file text to dropbox. Call it when all other methods of upload to cloud have failed.\"\n",
    "                  \"It is a fallback method to upload something. Use it only when upload to google drive fails.\")\n",
    "def upload_to_dropbox(file_name: Annotated[str, \"Name of the file to be uploaded. Required.\"],\n",
    "                      file_content: Annotated[str, \"Content of the file to be uploaded. Required.\"]) -> str:\n",
    "    print(f\"Successfully uploaded {file_name} to Dropbox.\")\n",
    "    return f\"Successfully uploaded {file_name} to Dropbox.\"\n"
   ],
   "id": "e058793704acdd0d",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:38:32.576699Z",
     "start_time": "2025-11-20T17:38:32.495069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import Field\n",
    "from langgraph.graph import add_messages\n",
    "from langchain_core.messages import AnyMessage\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[AnyMessage], add_messages] = Field([])\n",
    "    conversation_summary: Optional[str] = None\n",
    "    answer: Optional[str] = None\n",
    "    user_query: Optional[str] = None\n",
    "\n",
    "\n",
    "tools = [add_numbers,\n",
    "         fetch_current_weather,\n",
    "         rag_tool,\n",
    "         upload_to_google_drive,\n",
    "         upload_to_dropbox]\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "agent_node = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    state_schema=State\n",
    ")\n",
    "\n",
    "def should_continue(state: State) -> Literal[\"tools\", \"answer_saver\"]:\n",
    "    if state.messages[-1].tool_calls:\n",
    "        print(\"Routing to tools\")\n",
    "        return \"tools\"\n",
    "    print(\"Routing to next node\")\n",
    "    return \"answer_saver\"\n",
    "\n",
    "def planner_node(state: State) -> State:\n",
    "    res = llm.invoke([\n",
    "        SystemMessage(\"You are a task planning assistant. Given the conversation so far, \"\n",
    "                      \"create a plan of action to answer the user's last question. \"\n",
    "                      \"If tools are needed, specify which ones to use and in what order. \"\n",
    "                      \"If no tools are needed, indicate that as well.\"),\n",
    "    ] + state.messages)\n",
    "    print(\"Planner output:\", res.content)\n",
    "    state.messages.append(res)\n",
    "    return state\n",
    "\n",
    "def answer_saver(state: State) -> State:\n",
    "    print(\"Saving final answer to special field.\")\n",
    "    state.answer = state.messages[-1].content\n",
    "    return state\n",
    "\n",
    "def conversation_summarization_node(state: State) -> State:\n",
    "    print(\"Summarizing conversation so far.\")\n",
    "    res = llm.invoke([\n",
    "        SystemMessage(\"You are a conversation summarization assistant. \"\n",
    "                      \"Given the conversation so far, provide a concise summary \"\n",
    "                      \"of the key points discussed.\"),\n",
    "    ] + state.messages)\n",
    "    print(\"Summarization output:\", res.content)\n",
    "    state.messages.append(res)\n",
    "    state.conversation_summary = res.content\n",
    "    return state\n",
    "\n",
    "def build_graph():\n",
    "    workflow = StateGraph(State)\n",
    "\n",
    "    workflow.add_node(\"planner\", planner_node)\n",
    "    workflow.add_node(\"agent\", agent_node)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "    workflow.add_node(\"summarization\", conversation_summarization_node)\n",
    "    workflow.add_node(\"answer_saver\", answer_saver)\n",
    "\n",
    "    workflow.add_edge(START, \"planner\")\n",
    "    workflow.add_edge(\"planner\", \"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue\n",
    "    )\n",
    "    workflow.add_edge(\"answer_saver\", \"summarization\")\n",
    "    workflow.add_edge(\"summarization\", END)\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return workflow.compile().with_config(callbacks=[langfuse_handler])"
   ],
   "id": "ccad81e24df955ea",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:39:26.812237Z",
     "start_time": "2025-11-20T17:38:34.695068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graph = build_graph()\n",
    "\n",
    "res = State(**graph.invoke({\n",
    "    \"messages\": [\n",
    "        SystemMessage(\"You are a helpful assistant that can use tools to answer user questions.\"),\n",
    "        HumanMessage(\"Upload a file report.txt with content 'This is a sample report.' to cloud and also tell me the weather in Tokyo, Japan.\")\n",
    "    ]\n",
    "}))"
   ],
   "id": "9dfcbf9e8f0b9b44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planner output: Plan of Action:\n",
      "\n",
      "1. Create a file named report.txt with the content \"This is a sample report.\"\n",
      "2. Upload the created file to the cloud (using the appropriate file upload tool).\n",
      "3. Use a weather tool to fetch and display the current weather in Tokyo, Japan.\n",
      "4. Provide both the link/access to the uploaded file and the weather information to the user.\n",
      "\n",
      "Tools Needed:\n",
      "\n",
      "- File creation/upload tool\n",
      "- Weather information tool\n",
      "\n",
      "Order of Execution:\n",
      "\n",
      "1. Create and upload the report.txt file to the cloud.\n",
      "2. Fetch the current weather in Tokyo, Japan.\n",
      "3. Respond with the upload details and weather information.\n",
      "Failed to upload report.txt to Google Drive.\n",
      "Successfully uploaded report.txt to Dropbox.\n",
      "Routing to next node\n",
      "Saving final answer to special field.\n",
      "Summarizing conversation so far.\n",
      "Summarization output: Here is the information you requested:\n",
      "\n",
      "1. The file report.txt with the content \"This is a sample report.\" has been successfully uploaded to Dropbox.\n",
      "2. The current weather in Tokyo, Japan is sunny with a temperature of -19°C.\n",
      "\n",
      "If you need a link to the uploaded file or more details, please let me know!\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "state = res\n",
    "state.messages += HumanMessage(\"Now tell me a sci-fy movie plot.\")\n",
    "res = graph.invoke(state)"
   ],
   "id": "cc82bcbd93c15420"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89ed4dd2be9e2c74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "84317dfef93c21e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add observability with LangFuse",
   "id": "667bf241efd6ed65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T17:38:11.137903Z",
     "start_time": "2025-11-20T17:38:06.106509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "langfuse = Langfuse(\n",
    "  secret_key=\"sk-lf-ad603960-aad1-482e-8c78-79eda9b5e8f3\",\n",
    "  public_key=\"pk-lf-c209d32a-cea6-473f-8ce4-f8c7d6a4bd70\",\n",
    "  host=\"http://127.0.0.1:3000\"\n",
    ")\n",
    "\n",
    "langfuse_handler = CallbackHandler()\n",
    "# workflow.compile().with_config(callbacks=[langfuse_handler])"
   ],
   "id": "e2369294f781cd1b",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2bb653bd5cb25fe1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
